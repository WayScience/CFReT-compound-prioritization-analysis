{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f14772b4",
            "metadata": {},
            "source": [
                "# Download CPJUMP1 Data\n",
                "\n",
                "This notebook documents the workflow for downloading and processing data from the JUMP Cell Painting dataset, available in the Cell Painting Gallery.\n",
                "\n",
                "We focus on datasets where cells have been perturbed by overexpression of genes using open reading frame (ORF) vectors, which artificially increase the production of specific proteins.\n",
                "\n",
                "Key steps in this workflow:\n",
                "- Load configuration and metadata from a YAML file.\n",
                "- Filter experimental metadata to include only plates with ORF perturbations.\n",
                "- Download each plate's data as a CSV file, convert it to Parquet format, and save it in the `./data` directory.\n",
                "\n",
                "Each individual plate data file is saved as a `parquet` file in the `./data` folder. If a file with the same name already exists, it will be replaced with the newly downloaded data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "7748e2b0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import pathlib\n",
                "import polars\n",
                "import time\n",
                "import tqdm\n",
                "\n",
                "sys.path.append(\"../../\")\n",
                "from utils import io_utils"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "40502901",
            "metadata": {},
            "source": [
                "Setting parameters for the notebook:\n",
                "\n",
                "- `pert_type (str)`: Perturbation of interest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "312290eb",
            "metadata": {},
            "outputs": [],
            "source": [
                "pert_type = \"orf\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3adc316e",
            "metadata": {},
            "source": [
                "Setting input and output paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "b7381913",
            "metadata": {},
            "outputs": [],
            "source": [
                "# setting config path\n",
                "config_path = pathlib.Path(\"../nb-configs.yaml\").resolve(strict=True)\n",
                "\n",
                "# setting results setting a data directory\n",
                "data_dir = pathlib.Path(\"./data\").resolve()\n",
                "data_dir.mkdir(exist_ok=True)\n",
                "\n",
                "# creating a metadata directory\n",
                "metadata_dir = (data_dir / \"metadata\").resolve()\n",
                "metadata_dir.mkdir(exist_ok=True)\n",
                "\n",
                "# creating a platemaps directory in the metadata directory\n",
                "platemap_dir = (metadata_dir / \"platemaps\").resolve()\n",
                "platemap_dir.mkdir(exist_ok=True)\n",
                "\n",
                "# creating a profiles directory in the metadata directory\n",
                "profiles_dir = (data_dir / \"profiles\").resolve()\n",
                "profiles_dir.mkdir(exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b69f09ce",
            "metadata": {},
            "source": [
                "Downloading the experimental metadata file and saving it into the `metadata` directory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "5b8bfe5f",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div><style>\n",
                            ".dataframe > thead > tr,\n",
                            ".dataframe > tbody > tr {\n",
                            "  text-align: right;\n",
                            "  white-space: pre-wrap;\n",
                            "}\n",
                            "</style>\n",
                            "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Batch</th><th>Plate_Map_Name</th><th>Assay_Plate_Barcode</th><th>Perturbation</th><th>Cell_type</th><th>Time</th><th>Density</th><th>Antibiotics</th><th>Cell_line</th><th>Time_delay</th><th>Times_imaged</th><th>Anomaly</th><th>Number_of_images</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>&quot;2020_11_04_CPJUMP1&quot;</td><td>&quot;JUMP-Target-1_orf_platemap&quot;</td><td>&quot;BR00117006&quot;</td><td>&quot;orf&quot;</td><td>&quot;A549&quot;</td><td>96</td><td>100</td><td>&quot;absent&quot;</td><td>&quot;Parental&quot;</td><td>&quot;Day0&quot;</td><td>1</td><td>&quot;Phalloidin&quot;</td><td>27648</td></tr><tr><td>&quot;2020_11_04_CPJUMP1&quot;</td><td>&quot;JUMP-Target-1_orf_platemap&quot;</td><td>&quot;BR00117020&quot;</td><td>&quot;orf&quot;</td><td>&quot;A549&quot;</td><td>48</td><td>100</td><td>&quot;absent&quot;</td><td>&quot;Parental&quot;</td><td>&quot;Day0&quot;</td><td>1</td><td>&quot;none&quot;</td><td>27648</td></tr><tr><td>&quot;2020_11_04_CPJUMP1&quot;</td><td>&quot;JUMP-Target-1_orf_platemap&quot;</td><td>&quot;BR00117021&quot;</td><td>&quot;orf&quot;</td><td>&quot;A549&quot;</td><td>48</td><td>100</td><td>&quot;absent&quot;</td><td>&quot;Parental&quot;</td><td>&quot;Day0&quot;</td><td>1</td><td>&quot;none&quot;</td><td>27648</td></tr><tr><td>&quot;2020_11_04_CPJUMP1&quot;</td><td>&quot;JUMP-Target-1_orf_platemap&quot;</td><td>&quot;BR00117022&quot;</td><td>&quot;orf&quot;</td><td>&quot;U2OS&quot;</td><td>48</td><td>100</td><td>&quot;absent&quot;</td><td>&quot;Parental&quot;</td><td>&quot;Day0&quot;</td><td>1</td><td>&quot;none&quot;</td><td>27648</td></tr><tr><td>&quot;2020_11_04_CPJUMP1&quot;</td><td>&quot;JUMP-Target-1_orf_platemap&quot;</td><td>&quot;BR00117023&quot;</td><td>&quot;orf&quot;</td><td>&quot;U2OS&quot;</td><td>48</td><td>100</td><td>&quot;absent&quot;</td><td>&quot;Parental&quot;</td><td>&quot;Day0&quot;</td><td>1</td><td>&quot;none&quot;</td><td>27648</td></tr></tbody></table></div>"
                        ],
                        "text/plain": [
                            "shape: (5, 13)\n",
                            "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
                            "│ Batch     ┆ Plate_Map ┆ Assay_Pla ┆ Perturbat ┆ … ┆ Time_dela ┆ Times_ima ┆ Anomaly   ┆ Number_o │\n",
                            "│ ---       ┆ _Name     ┆ te_Barcod ┆ ion       ┆   ┆ y         ┆ ged       ┆ ---       ┆ f_images │\n",
                            "│ str       ┆ ---       ┆ e         ┆ ---       ┆   ┆ ---       ┆ ---       ┆ str       ┆ ---      │\n",
                            "│           ┆ str       ┆ ---       ┆ str       ┆   ┆ str       ┆ i64       ┆           ┆ i64      │\n",
                            "│           ┆           ┆ str       ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
                            "│ 2020_11_0 ┆ JUMP-Targ ┆ BR0011700 ┆ orf       ┆ … ┆ Day0      ┆ 1         ┆ Phalloidi ┆ 27648    │\n",
                            "│ 4_CPJUMP1 ┆ et-1_orf_ ┆ 6         ┆           ┆   ┆           ┆           ┆ n         ┆          │\n",
                            "│           ┆ platemap  ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│ 2020_11_0 ┆ JUMP-Targ ┆ BR0011702 ┆ orf       ┆ … ┆ Day0      ┆ 1         ┆ none      ┆ 27648    │\n",
                            "│ 4_CPJUMP1 ┆ et-1_orf_ ┆ 0         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ platemap  ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│ 2020_11_0 ┆ JUMP-Targ ┆ BR0011702 ┆ orf       ┆ … ┆ Day0      ┆ 1         ┆ none      ┆ 27648    │\n",
                            "│ 4_CPJUMP1 ┆ et-1_orf_ ┆ 1         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ platemap  ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│ 2020_11_0 ┆ JUMP-Targ ┆ BR0011702 ┆ orf       ┆ … ┆ Day0      ┆ 1         ┆ none      ┆ 27648    │\n",
                            "│ 4_CPJUMP1 ┆ et-1_orf_ ┆ 2         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ platemap  ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│ 2020_11_0 ┆ JUMP-Targ ┆ BR0011702 ┆ orf       ┆ … ┆ Day0      ┆ 1         ┆ none      ┆ 27648    │\n",
                            "│ 4_CPJUMP1 ┆ et-1_orf_ ┆ 3         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "│           ┆ platemap  ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
                            "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# loading config file and setting experimental metadata URL\n",
                "nb_configs = io_utils.load_configs(config_path)\n",
                "CPJUMP1_exp_metadata_url = nb_configs[\"links\"][\"CPJUMP1-experimental-metadata-source\"]\n",
                "\n",
                "# read in the experimental metadata CSV file and only filter down to plays that\n",
                "# have an ORF perturbation\n",
                "exp_metadata = polars.read_csv(\n",
                "    CPJUMP1_exp_metadata_url, separator=\"\\t\", has_header=True, encoding=\"utf-8\"\n",
                ")\n",
                "\n",
                "# filtering the metadata to only includes plates that their perturbation types are orfs\n",
                "exp_metadata = exp_metadata.filter(exp_metadata[\"Perturbation\"].str.contains(\"orf\"))\n",
                "\n",
                "# save the experimental metadata as a csv file\n",
                "exp_metadata.write_csv(metadata_dir / \"CPJUMP1-experimental-metadata.tsv\", separator=\"\\t\")\n",
                "\n",
                "# display\n",
                "exp_metadata.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3d2922ea",
            "metadata": {},
            "source": [
                "To efficiently organize and download the CPJUMP1 data, we generate a dictionary (`batch_and_time_delay_dict`) that maps each experimental timepoint (e.g., Day0, Day1, Week2, Week4, DL) to its corresponding batch identifier. \n",
                "\n",
                "This mapping enables us to:\n",
                "- Group and save data files according to their acquisition timepoints after initial treatment.\n",
                "- Treat each delayed timepoint as a distinct batch for downstream processing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "1b9e9b1d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Delayed timepoints and their corresponding batches:\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "{'Day0': '2020_11_04_CPJUMP1',\n",
                            " 'Day1': '2020_11_18_CPJUMP1_TimepointDay1',\n",
                            " 'Day4': '2020_11_19_TimepointDay4',\n",
                            " 'Week2': '2020_12_02_CPJUMP1_2WeeksTimePoint',\n",
                            " 'Week4': '2020_12_07_CPJUMP1_4WeeksTimePoint'}"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# extracting the unique batches and time delays from the experimental metadata\n",
                "batch_and_time_delay = exp_metadata[[\"Batch\", \"Time_delay\"]].unique(maintain_order=True)\n",
                "\n",
                "# creating a dictionary to store the batch and time delay information\n",
                "# {\"time of delay\": \"Batch\"} is the format of the dictionary\n",
                "batch_and_time_delay_dict = {}\n",
                "for row in batch_and_time_delay.rows(named=True):\n",
                "\n",
                "    # extracting Batch and Time_delay from the row\n",
                "    batch = row[\"Batch\"]\n",
                "    time_delay = row[\"Time_delay\"]\n",
                "    \n",
                "    # ignore CPJUMP1_DL batch\n",
                "    # there is no negative controled wells for this batch \n",
                "    if batch.endswith(\"CPJUMP1_DL\"):\n",
                "        continue\n",
                "    else:\n",
                "        batch_and_time_delay_dict[time_delay] = batch\n",
                "\n",
                "print(\"Delayed timepoints and their corresponding batches:\")\n",
                "batch_and_time_delay_dict"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "aaae36ee",
            "metadata": {},
            "source": [
                "Downloading Aggregated Profiles for Selected `pert_type`\n",
                "\n",
                "For each time point, all plates associated with the selected perturbation type (`pert_type`) will be downloaded. After downloading, the data from all plates for a given time point will be concatenated into a single file. Each output file will be prefixed with the corresponding time point to clearly indicate its contents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "77cbb290",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Downloading plates for Day0: 100%|██████████| 9/9 [00:12<00:00,  1.36s/it]\n",
                        "Downloading plates for Day1: 100%|██████████| 8/8 [00:10<00:00,  1.29s/it]\n",
                        "Downloading plates for Day4: 100%|██████████| 8/8 [00:10<00:00,  1.34s/it]\n",
                        "Downloading plates for Week2: 100%|██████████| 8/8 [00:10<00:00,  1.36s/it]\n",
                        "Downloading plates for Week4: 100%|██████████| 8/8 [00:11<00:00,  1.39s/it]\n"
                    ]
                }
            ],
            "source": [
                "# setting CPJUMP1 source link, this points to the main directory where all the plate data\n",
                "# is stored\n",
                "header_link = nb_configs[\"links\"][\"CPJUMP1-profiles-source\"]\n",
                "\n",
                "# iterating over each time point\n",
                "for delayed_time_point, batch_name in batch_and_time_delay_dict.items():\n",
                "\n",
                "    # filter the experiential metadata to only include the plates that correspond \n",
                "    # to the current time point\n",
                "    exp_metadata_filtered = exp_metadata.filter(\n",
                "        exp_metadata[\"Batch\"] == batch_name\n",
                "    )\n",
                "    if exp_metadata_filtered.is_empty():\n",
                "        raise ValueError(\n",
                "            f\"No plates found for batch {batch_name} at time point {delayed_time_point}. \"\n",
                "            \"Please check the experimental metadata.\"\n",
                "        )\n",
                "\n",
                "    # get all the plate names for the current time points\n",
                "    plate_names = exp_metadata_filtered[\"Assay_Plate_Barcode\"].to_list()\n",
                "    \n",
                "    # iterate over each plate name and download the data\n",
                "    loaded_profiles_df = []\n",
                "    for plate_name in tqdm.tqdm(plate_names, desc=f\"Downloading plates for {delayed_time_point}\"):\n",
                "        # set the profile src end point\n",
                "        profile_end_point = f\"{batch_name}/{plate_name}/{plate_name}_normalized_feature_select_negcon_batch.csv.gz\"\n",
                "\n",
                "        # set the full URL for the profile\n",
                "        profile_url = f\"{header_link}/{profile_end_point}\"\n",
                "        \n",
                "        # downloading profile data from the URL link\n",
                "        # if download fails, raise an error\n",
                "        try:\n",
                "            loaded_profile = polars.read_csv(\n",
                "                profile_url,\n",
                "                separator=\",\",\n",
                "                has_header=True\n",
                "            )\n",
                "\n",
                "            # adding a small delay to avoid overwhelming the server\n",
                "            time.sleep(0.7)  \n",
                "        except Exception as e:\n",
                "            raise ValueError(f\"Error downloading {plate_name} for {delayed_time_point}: {e}\")\n",
                "\n",
                "        # store the plate data in a list\n",
                "        loaded_profiles_df.append(loaded_profile)\n",
                "\n",
                "    # concatenate all the loaded profiles into a single DataFrame and save \n",
                "    loaded_profiles_df = polars.concat(loaded_profiles_df, how=\"vertical\")\n",
                "    \n",
                "    # save the concatenated profiles to a parquet file\n",
                "    output_file = (profiles_dir / f\"{batch_name}_profiles.parquet\").resolve()\n",
                "    loaded_profiles_df.write_parquet(output_file)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "902b4c05",
            "metadata": {},
            "source": [
                "Downloading the platemaps associated with the selected `pert_type`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "a0824e04",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div><style>\n",
                            ".dataframe > thead > tr,\n",
                            ".dataframe > tbody > tr {\n",
                            "  text-align: right;\n",
                            "  white-space: pre-wrap;\n",
                            "}\n",
                            "</style>\n",
                            "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>well_position</th><th>broad_sample</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;A01&quot;</td><td>&quot;ccsbBroad304_00900&quot;</td></tr><tr><td>&quot;A02&quot;</td><td>&quot;ccsbBroad304_07795&quot;</td></tr><tr><td>&quot;A03&quot;</td><td>&quot;ccsbBroad304_02826&quot;</td></tr><tr><td>&quot;A04&quot;</td><td>&quot;ccsbBroad304_01492&quot;</td></tr><tr><td>&quot;A05&quot;</td><td>&quot;ccsbBroad304_00691&quot;</td></tr></tbody></table></div>"
                        ],
                        "text/plain": [
                            "shape: (5, 2)\n",
                            "┌───────────────┬────────────────────┐\n",
                            "│ well_position ┆ broad_sample       │\n",
                            "│ ---           ┆ ---                │\n",
                            "│ str           ┆ str                │\n",
                            "╞═══════════════╪════════════════════╡\n",
                            "│ A01           ┆ ccsbBroad304_00900 │\n",
                            "│ A02           ┆ ccsbBroad304_07795 │\n",
                            "│ A03           ┆ ccsbBroad304_02826 │\n",
                            "│ A04           ┆ ccsbBroad304_01492 │\n",
                            "│ A05           ┆ ccsbBroad304_00691 │\n",
                            "└───────────────┴────────────────────┘"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# downloading the plate maps\n",
                "pert_platemap_url = nb_configs[\"links\"][\"CPJUMP1-platemaps-source\"]\n",
                "pert_platemap_name = f\"JUMP-Target-1_{pert_type}_platemap.txt\"\n",
                "\n",
                "# constructing the full URL for the plate map\n",
                "platemap_url = f\"{pert_platemap_url}/{pert_platemap_name}\"\n",
                "\n",
                "# downloading the plate map\n",
                "platemap_df = polars.read_csv(platemap_url, separator=\"\\t\")\n",
                "\n",
                "# save it to the platemap directory\n",
                "platemap_df.write_csv(platemap_dir / pert_platemap_name)\n",
                "\n",
                "# display the first few rows of the plate map\n",
                "platemap_df.head()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "buscar",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
